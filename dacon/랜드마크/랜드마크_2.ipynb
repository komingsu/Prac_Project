{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d413b759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:43:14.566510Z",
     "start_time": "2022-07-16T07:43:14.550169Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime, os, time, pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import applications, losses, models, layers, optimizers, callbacks, utils\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a8b5890",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:43:14.911409Z",
     "start_time": "2022-07-16T07:43:14.904407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices(\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "321d45b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:44:07.047441Z",
     "start_time": "2022-07-16T07:44:07.034441Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(\"D:Dataset/랜드마크 이미지/Training/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abe4eb35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:44:07.605461Z",
     "start_time": "2022-07-16T07:44:07.222376Z"
    }
   },
   "outputs": [],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg'))) # 총 이미지 개수\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'), shuffle=False)\n",
    "list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f6258ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:44:07.621472Z",
     "start_time": "2022-07-16T07:44:07.606461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6.25격전지개미고개' 'BRT작은미술관' '가락마을20단지호반베르디움5차아파트' '가락마을3단지호반베르디움4차아파트'\n",
      " '가온마을1단지힐스테이트세종2차' '가재마을세종호반베르디움2단지아파트' '고운뜰전망대' '국립세종도서관' '국립세종수목원'\n",
      " '국립조세박물관' '금강수목원' '금강수변공원' '금강자연휴양림' '금남남산영당' '금남모인당' '금남문절사' '김종서장군묘소'\n",
      " '나성독락정' '덕성서원' '덕천군사우' '도램마을10단지호반베르디움어반시티아파트' '도램마을15단지힐스테이트아파트'\n",
      " '밀양박씨오충정려' '박산리작약골쌍탑제' '범지기마을10단지푸르지오아파트' '범지기마을7단지호반베르디움에코시티아파트'\n",
      " '범지기마을8단지푸르지오아파트' '베어트리파크' '병산사' '부강성당' '부강초등학교강당' '비암사' '새뜸1단지메이저시티푸르지오'\n",
      " '새뜸마을10단지더샵힐스테이트아파트' '새뜸마을11단지더샵힐스테이트아파트' '새뜸마을14단지더샵힐스테이트아파트'\n",
      " '새뜸마을5단지아이파크메이저아파트' '새뜸마을6단지힐스테이트메이저아파트' '성요한성당' '세종e편한세상푸르지오아파트'\n",
      " '세종고속시외버스터미널' '세종대곡리삼층석탑' '세종시립민속박물관' '세종전통장류박물관' '세종특별자치시마을기록문화관'\n",
      " '세종행복도시홍보관' '세종호수공원' '세종힐스테이트3차' '수루배마을4단지더샵예미지' '수루배마을6단지세종더샵예미지'\n",
      " '연기대첩비공원' '연기봉산동의향나무' '연기향교' '연기향토박물관' '연동송용리마애여래입상' '연화사' '영평사' '은하수공원'\n",
      " '자성사' '전의비암사극락보전' '전의비암사삼층석탑' '전의향교' '조천연꽃공원' '조치원문화정원' '조치원봉산영당'\n",
      " '조치원신흥e편한세상아파트' '조치원신흥푸르지오아파트' '조치원역경부선' '조치원자이아파트' '조치원죽림푸르지오아파트'\n",
      " '천주교대전교구세종성프란치스코성당' '첫마을4단지푸르지오아파트' '첫마을5단지푸르지오아파트' '첫마을6단지힐스테이트아파트'\n",
      " '첫마을7단지삼성래미안아파트' '초려역사공원' '충청남도산림박물관' '한뜰마을1단지상록데시앙아파트'\n",
      " '한뜰마을2단지더샵센트럴시티아파트' '한뜰마을3단지더샵레이크파크아파트' '해들마을6단지e편한세상세종리버파크' '황룡사'\n",
      " '힐스테이트세종리버파크7단지' '힐스테이트세종리버파크8단지'] 84\n"
     ]
    }
   ],
   "source": [
    "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
    "print(class_names, len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "694435b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:44:07.637476Z",
     "start_time": "2022-07-16T07:44:07.622472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10537\n",
      "1859\n"
     ]
    }
   ],
   "source": [
    "val_size = int(image_count * 0.15)\n",
    "train_ds = list_ds.skip(val_size) # 20% 를 넘김\n",
    "valid_ds = list_ds.take(val_size) # 20% 를 가짐 \n",
    "NUM_TRAIN = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "NUM_VALID = tf.data.experimental.cardinality(valid_ds).numpy()\n",
    "print(tf.data.experimental.cardinality(train_ds).numpy())\n",
    "print(tf.data.experimental.cardinality(valid_ds).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ce761f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:44:07.668480Z",
     "start_time": "2022-07-16T07:44:07.663480Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "SIZE = 224\n",
    "img_height = SIZE\n",
    "img_width = SIZE\n",
    "image_size=(img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "44aa29af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:44:07.981601Z",
     "start_time": "2022-07-16T07:44:07.973185Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  one_hot = parts[-2] == class_names\n",
    "  # Integer encode the label\n",
    "  return tf.argmax(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c28abe4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:44:08.245868Z",
     "start_time": "2022-07-16T07:44:08.231059Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    # resize the image to the desired size\n",
    "    return tf.image.resize(img, [img_height, img_width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "29ff6504",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:44:08.495923Z",
     "start_time": "2022-07-16T07:44:08.484880Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1eac0413",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:44:09.206411Z",
     "start_time": "2022-07-16T07:44:08.744628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (224, 224, 3)\n",
      "Label:  56\n",
      "Image shape:  (224, 224, 3)\n",
      "Label:  28\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "valid_ds = valid_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "for image, label in train_ds.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())\n",
    "    \n",
    "for image, label in valid_ds.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c06d0bda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:44:09.237621Z",
     "start_time": "2022-07-16T07:44:09.216413Z"
    }
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b9d1672",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:44:11.502492Z",
     "start_time": "2022-07-16T07:44:11.488487Z"
    }
   },
   "outputs": [],
   "source": [
    "def configure_for_performance_train(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def configure_for_performance_test(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = configure_for_performance_train(train_ds)\n",
    "valid_ds = configure_for_performance_test(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "34d57b26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:44:15.917595Z",
     "start_time": "2022-07-16T07:44:14.773014Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model = applications.EfficientNetB0(input_shape=(img_height,img_width,3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False # 베이스 모델은 학습하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cc88ca18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:44:16.990088Z",
     "start_time": "2022-07-16T07:44:16.508686Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_eff_model():\n",
    "    # Top\n",
    "    x = layers.Input(shape=(img_height, img_width, 3))\n",
    "    \n",
    "    if tf.data == train_ds:\n",
    "        y = img_augmentation(x)\n",
    "    \n",
    "    y = base_model(x, training=False)\n",
    "\n",
    "    # Rebuild\n",
    "    y = layers.GlobalAveragePooling2D(name=\"avg_pool\")(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    top_dropout_rate = 0.2\n",
    "    y = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(y)\n",
    "    y = layers.Dense(84, activation=\"softmax\", name=\"Pred\")(y)\n",
    "    \n",
    "    # compile\n",
    "    model = models.Model(x, y, name=\"EfficientNet\")\n",
    "    optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "    loss = losses.SparseCategoricalCrossentropy()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[\"acc\"])\n",
    "    return model\n",
    "model = build_eff_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e1b4c759",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:44:18.968463Z",
     "start_time": "2022-07-16T07:44:18.965476Z"
    }
   },
   "outputs": [],
   "source": [
    "ckp = callbacks.ModelCheckpoint(\n",
    "    \"model_2.h5\",  # 경로\n",
    "    save_best_only=True,  # 가장 높은 점수의 모델만\n",
    "    monitor=\"val_acc\")  # val_acc 를 보고 판단\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor=\"val_acc\",\n",
    "    patience=7)  # 7번까지는 기다릴수있다(낮아지는 횟수가 아니라 최고점 이후 점수가 상승하지 않는 횟수)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_acc\",\n",
    "    patience=3,\n",
    "    factor=0.1  # 학습률을 1/10 으로 줄임\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a034db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:52:28.861569Z",
     "start_time": "2022-07-16T07:44:25.167775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "330/330 [==============================] - 116s 281ms/step - loss: 1.2639 - acc: 0.7681 - val_loss: 0.1904 - val_acc: 0.9543\n",
      "Epoch 2/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.1420 - acc: 0.9679 - val_loss: 0.1815 - val_acc: 0.9699\n",
      "Epoch 3/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.1629 - acc: 0.9696 - val_loss: 0.1862 - val_acc: 0.9710\n",
      "Epoch 4/100\n",
      "330/330 [==============================] - 19s 59ms/step - loss: 0.1524 - acc: 0.9782 - val_loss: 0.2711 - val_acc: 0.9699\n",
      "Epoch 5/100\n",
      "330/330 [==============================] - 19s 59ms/step - loss: 0.1097 - acc: 0.9809 - val_loss: 0.2992 - val_acc: 0.9656\n",
      "Epoch 6/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.1356 - acc: 0.9817 - val_loss: 0.3174 - val_acc: 0.9672\n",
      "Epoch 7/100\n",
      "330/330 [==============================] - 19s 59ms/step - loss: 0.0755 - acc: 0.9883 - val_loss: 0.1816 - val_acc: 0.9785\n",
      "Epoch 8/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0197 - acc: 0.9950 - val_loss: 0.1465 - val_acc: 0.9822\n",
      "Epoch 9/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0069 - acc: 0.9981 - val_loss: 0.1306 - val_acc: 0.9849\n",
      "Epoch 10/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0089 - acc: 0.9979 - val_loss: 0.1263 - val_acc: 0.9855\n",
      "Epoch 11/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0098 - acc: 0.9978 - val_loss: 0.1244 - val_acc: 0.9860\n",
      "Epoch 12/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0046 - acc: 0.9982 - val_loss: 0.1068 - val_acc: 0.9876\n",
      "Epoch 13/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0071 - acc: 0.9980 - val_loss: 0.1009 - val_acc: 0.9887\n",
      "Epoch 14/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0034 - acc: 0.9987 - val_loss: 0.1046 - val_acc: 0.9887\n",
      "Epoch 15/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0040 - acc: 0.9992 - val_loss: 0.0918 - val_acc: 0.9882\n",
      "Epoch 16/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0985 - val_acc: 0.9871\n",
      "Epoch 17/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0975 - val_acc: 0.9866\n",
      "Epoch 18/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0026 - acc: 0.9986 - val_loss: 0.0973 - val_acc: 0.9871\n",
      "Epoch 19/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0029 - acc: 0.9990 - val_loss: 0.0938 - val_acc: 0.9887\n",
      "Epoch 20/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0037 - acc: 0.9991 - val_loss: 0.0943 - val_acc: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b5f5be0c08>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=100,\n",
    "    validation_data=valid_ds,\n",
    "    callbacks=[ckp, early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94c70ae",
   "metadata": {},
   "source": [
    "* 미세조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5c854623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:54:10.837306Z",
     "start_time": "2022-07-16T07:54:10.829318Z"
    }
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    if \"Conv2D\" in str(layer):\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "58e46bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T07:57:41.567941Z",
     "start_time": "2022-07-16T07:54:29.734354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "330/330 [==============================] - 19s 57ms/step - loss: 9.2406e-04 - acc: 0.9997 - val_loss: 0.0937 - val_acc: 0.9882\n",
      "Epoch 2/100\n",
      "330/330 [==============================] - 19s 57ms/step - loss: 0.0019 - acc: 0.9991 - val_loss: 0.0935 - val_acc: 0.9882\n",
      "Epoch 3/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0937 - val_acc: 0.9887\n",
      "Epoch 4/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0016 - acc: 0.9993 - val_loss: 0.0930 - val_acc: 0.9887\n",
      "Epoch 5/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0929 - val_acc: 0.9887\n",
      "Epoch 6/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0934 - val_acc: 0.9887\n",
      "Epoch 7/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0042 - acc: 0.9989 - val_loss: 0.0936 - val_acc: 0.9882\n",
      "Epoch 8/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0935 - val_acc: 0.9887\n",
      "Epoch 9/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.0933 - val_acc: 0.9887\n",
      "Epoch 10/100\n",
      "330/330 [==============================] - 19s 58ms/step - loss: 0.0020 - acc: 0.9993 - val_loss: 0.0931 - val_acc: 0.9882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b660e228c8>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,\n",
    "          epochs=100,\n",
    "          validation_data=valid_ds,\n",
    "          callbacks=[ckp, early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32097d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
